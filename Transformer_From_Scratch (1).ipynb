{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Wiki Transformer from Scratch"
      ],
      "metadata": {
        "id": "axO1Xv2Bz7yh"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bt54PLNXcQfd"
      },
      "source": [
        "This project is inspired by Andrej Karpathy's work at: https://www.youtube.com/watch?v=kCc8FmEb1nY\n",
        "\n",
        "We will be building a decoder-only Transformer from scratch, and training it on a corpus of Wikipedia data, to try and generate Wikipedia-style text. \n",
        "\n",
        "We will be training on: Wikitext - V2. Wikitext - V2 is a 2M word subset of the Wikipedia corpus. \n",
        "The goal for the project is to: \n",
        "\n",
        "Plan: \n",
        "- define a decoder transformer architecture\n",
        "- train on the WikiText dataset \n",
        "- Generate infinite Wikipedia-like text \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Imports \n"
      ],
      "metadata": {
        "id": "1s8KhINRwKRh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch \n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "0iICF7alwV-i"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#device agnostic code\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "NJGvrfWqwMiF"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Glance at data \n",
        "*Take a peek at data to see if it's what we want"
      ],
      "metadata": {
        "id": "LIeT6bkFGu3A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8WGeHlOpGuRG",
        "outputId": "d18ecae5-ad6b-42af-ebd4-01916e491db8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.9.0-py3-none-any.whl (462 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.8/462.8 KB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xxhash\n",
            "  Downloading xxhash-3.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.0/213.0 KB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets) (1.3.5)\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.14-py38-none-any.whl (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.0/132.0 KB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (2023.1.0)\n",
            "Requirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (2.25.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from datasets) (23.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (4.64.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (6.0)\n",
            "Collecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets) (3.8.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from datasets) (1.21.6)\n",
            "Collecting huggingface-hub<1.0.0,>=0.2.0\n",
            "  Downloading huggingface_hub-0.12.0-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.8.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (22.2.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (2.1.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.9.0)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Collecting urllib3<1.27,>=1.21.1\n",
            "  Downloading urllib3-1.26.14-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Installing collected packages: xxhash, urllib3, multiprocess, responses, huggingface-hub, datasets\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed datasets-2.9.0 huggingface-hub-0.12.0 multiprocess-0.70.14 responses-0.18.0 urllib3-1.26.14 xxhash-3.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -c \"from datasets import load_dataset; print(load_dataset('squad', split='train')[0])\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HjOiZVLcIW24",
        "outputId": "2224b0ad-82f9-4ef4-ae93-efce5513895f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading builder script: 100% 5.27k/5.27k [00:00<00:00, 3.17MB/s]\n",
            "Downloading metadata: 100% 2.36k/2.36k [00:00<00:00, 1.76MB/s]\n",
            "Downloading readme: 100% 7.67k/7.67k [00:00<00:00, 6.69MB/s]\n",
            "Downloading and preparing dataset squad/plain_text to /root/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453...\n",
            "Downloading data files:   0% 0/2 [00:00<?, ?it/s]\n",
            "Downloading data:   0% 0.00/8.12M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading data: 10.8MB [00:00, 108MB/s]        \u001b[A\n",
            "Downloading data: 30.3MB [00:00, 108MB/s]\n",
            "Downloading data files:  50% 1/2 [00:00<00:00,  1.79it/s]\n",
            "Downloading data: 4.85MB [00:00, 124MB/s]        \n",
            "Downloading data files: 100% 2/2 [00:00<00:00,  2.32it/s]\n",
            "Extracting data files: 100% 2/2 [00:00<00:00, 1491.04it/s]\n",
            "Dataset squad downloaded and prepared to /root/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453. Subsequent calls will reuse this data.\n",
            "{'id': '5733be284776f41900661182', 'title': 'University_of_Notre_Dame', 'context': 'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.', 'question': 'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?', 'answers': {'text': ['Saint Bernadette Soubirous'], 'answer_start': [515]}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset_builder\n",
        "ds_builder = load_dataset_builder(\"wikitext\", 'wikitext-2-v1')"
      ],
      "metadata": {
        "id": "y-y8n8lIIm9M",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "ba867cccc9a6453ea16951aae5d2f430",
            "a9935b69038c45239bc75b31a02266b7",
            "02e5b6ea02644f24b806e9f61f4840c2",
            "5852ae05ec26487f853ea23a904dc8c8",
            "ff8f6fb020b841d49dbe97c061ada31d",
            "46f33902e1af475db6a8a43d7511da53",
            "4527aee4d59d410093c8da0ab9993650",
            "5cb573d9f32c49b1bc5d7804428acb55",
            "58e25675280c4e2c9eb1e44a9953c179",
            "ae135abb18a546ee9a583512f52cf36e",
            "5e940f18cf8b46148b239cc40d9407d3",
            "1372b9f8a029450eb8a066a64ab118c2",
            "298e42a151264bd6be317f186d1ff693",
            "f589d6fc97054a3898acc2b0a986d746",
            "31d95c6e5fc546159e23f1eca18c2643",
            "eba21c3b03df49c3957ecbdcf1a423e9",
            "409b87655b454f1798c52a0f8d193842",
            "f768bf34683b443781a274abb170133f",
            "0d0c059a4a7f40caab468952ae876334",
            "6ea8b2a81b6c4ef29bbaefb6d634e520",
            "9331782c13aa49998a945e95f2769fbf",
            "3100d1917f994239ac19a141831c32c5",
            "028ab6867d9442a08ab9f99bb500fdd3",
            "6c1c54ca091546979cf968d0d2804972",
            "6ce6398ddc78461a9371148aa52acdd0",
            "9af099beea444a1a8eda5e0f0bfd9e16",
            "f0c94d33310b4b418d8363fac019d277",
            "6d18d7b1bd33431c9514b157667bb366",
            "b1182ad3389f4b8a906320e0d3847a13",
            "f330699db41244558577858a6124c6a5",
            "12ee7350c02049a0b26a3789f970d8ea",
            "57df40a14dda4234abe1dd81e95eb2cb",
            "046da7798716402b91c80ba665d48c75"
          ]
        },
        "outputId": "0bc79a9a-d4c2-4c9c-ecf2-1468678cd13d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/8.48k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ba867cccc9a6453ea16951aae5d2f430"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading metadata:   0%|          | 0.00/6.84k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1372b9f8a029450eb8a066a64ab118c2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/9.25k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "028ab6867d9442a08ab9f99bb500fdd3"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#inspect dataset description \n",
        "ds_builder.info.description"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "xzDbQk6HIqFR",
        "outputId": "32695f31-b3d2-44fd-d3db-eeaa27bd50fa"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The WikiText language modeling dataset is a collection of over 100 million tokens extracted from the set of verified\\n Good and Featured articles on Wikipedia. The dataset is available under the Creative Commons Attribution-ShareAlike\\n License.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#inspect dataset features \n",
        "ds_builder.info.features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_H47eor2JMFe",
        "outputId": "638d6f01-6f8e-4598-b279-cea8b3c72412"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': Value(dtype='string', id=None)}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that the wiki dataset is simply text with data type \"string\". No label is needed because we are not doing classification."
      ],
      "metadata": {
        "id": "sPuG_0_8JRBs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Load Dataset \n"
      ],
      "metadata": {
        "id": "9o38AfGrJbV7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "See what splits the dataset has"
      ],
      "metadata": {
        "id": "amjqjHVdKZ_h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import get_dataset_split_names\n",
        "get_dataset_split_names(\"wikitext\", 'wikitext-2-v1')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tW4T0KN5J5nt",
        "outputId": "395a60a3-3be5-48b4-d1aa-38eb4ae36dc5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['test', 'train', 'validation']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see there is train, test and validation sets"
      ],
      "metadata": {
        "id": "W0v6CyFOKCLL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download the training data "
      ],
      "metadata": {
        "id": "13_frfkdKcgk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"wikitext\", 'wikitext-2-v1', split=\"train\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169,
          "referenced_widgets": [
            "02fc2ca2cdc74acab607718e937b596c",
            "b3204f86c5074df6aee36c4e425dbd44",
            "d47eb4c6b9bd4d69869b5563431b74ee",
            "22789ce38ca440f9a5a95402c4c9e820",
            "5c26a123362b4ae1825f8eeb6d8acdd8",
            "dff48812f6c84f14849a071527ab48e9",
            "7dc3f968a96f434ba28351a7ca29c261",
            "99573fc97ea547dda58597e7f38ce69a",
            "0125b97100b84b0a8016c61a5cd89545",
            "da49032889124583a9ff60ea6136d25e",
            "6e43aad7fb6348d0984737839ede1d9a",
            "b53124f1d4a64a69a1b59fdec44b03f4",
            "3de1a2ba7b2a4eaebe3acb4a05c99122",
            "2c85382c6dbc402889068b6607789d10",
            "2c5f0e7e5ea844cd9ee425ae11f88d18",
            "a491d355fbca43e3aca490da7232cc26",
            "677f932cabd84eeb93a5ac3ff7fe8e1f",
            "b7c5cc48800145c49d4d00bcbce3bbce",
            "e95f4aac81a84110962cb184bf62b9d0",
            "98ae7a53a2424b07aab242ef61faed79",
            "3c42a0b4e5044bd89486927117549b62",
            "a1decc3d53c64098ae41d34a51543401",
            "f399db1aedbf4f56adfe3372d9759faf",
            "0fd2911f67a14eee9527e1bc74c69b87",
            "f98efed3bca34965ac32f956648c1d49",
            "6018858047ff4cf29467e1055d7bf55b",
            "a3b9d99bfbf84031a5d43cf1c11e1405",
            "b6bae316d26346c9b3eba054d80cdfea",
            "9ccf4295f8a2463a8a234d59832a2082",
            "cbe0fb15f32442db8ea303206bd81c5d",
            "2c575b12ce3a4e5994abe50d827c907b",
            "eb4c711ac77645a1bfacf3637f0c8f5f",
            "01715a7320274ae1a183a5e5399708e5",
            "23355283cdbc4cde93087b4161f7203a",
            "f4a964f34204469aa9136a8f74acd0c6",
            "9f7ce7b97f0f40cfaed12831bfe6ff62",
            "bbf233cc99904a84911bd7ff0abff031",
            "89ba75bdfe864339b911a477e317fd5e",
            "84583ca2a9e8422b950fde25493e9e35",
            "b275a83414764153aa6fb9906e270633",
            "d74c8456a78f4cb3b1d494f09aec3303",
            "d836937cd77f41e09674ec359a01cb30",
            "3bb4c32b32d44d09b88596605849e812",
            "5591742fe314482e9b2c05c352da79ef"
          ]
        },
        "id": "dXVz44UGJZWm",
        "outputId": "6dc91fa7-43ce-47f3-9131-fe406b570ce5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading and preparing dataset wikitext/wikitext-2-v1 to /root/.cache/huggingface/datasets/wikitext/wikitext-2-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/4.48M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "02fc2ca2cdc74acab607718e937b596c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/4358 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b53124f1d4a64a69a1b59fdec44b03f4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/36718 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f399db1aedbf4f56adfe3372d9759faf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/3760 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "23355283cdbc4cde93087b4161f7203a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset wikitext downloaded and prepared to /root/.cache/huggingface/datasets/wikitext/wikitext-2-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126. Subsequent calls will reuse this data.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check out the dataset object "
      ],
      "metadata": {
        "id": "5wJ08LFnKhOJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHkTBqBLKNQx",
        "outputId": "64b3000c-6ea5-414f-e68d-b1886e631958"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text'],\n",
              "    num_rows: 36718\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are 36718 rows of text. Let's explore more by indexing into the dataset"
      ],
      "metadata": {
        "id": "K6Bo2hkUKsAL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HS0EQKfbKjFl",
        "outputId": "21ad9d07-bdc2-4159-a861-44f1dae05763"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': ['', ' = Valkyria Chronicles III = \\n', '']}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pre - Pre Processing\n"
      ],
      "metadata": {
        "id": "nNDsWv2zLWjC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we want to pre process the text. Since we are going to be buliding a character-level transformer, to keep it simple, we will transform our Datasets object into a single string. "
      ],
      "metadata": {
        "id": "NMzvDnT4LUsD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#It is easier for me to convert to pandas df\n",
        "import pandas as pd\n",
        "df_pandas = pd.DataFrame(dataset)"
      ],
      "metadata": {
        "id": "lK1gDd76PbRl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pandas.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "bJtWOfSwPkp9",
        "outputId": "8e89135b-9667-465e-ddc9-a9c1f0bf2b77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text\n",
              "0                                                   \n",
              "1                     = Valkyria Chronicles III = \\n\n",
              "2                                                   \n",
              "3   Senjō no Valkyria 3 : <unk> Chronicles ( Japa...\n",
              "4   The game began development in 2010 , carrying..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f8855cbc-057b-4338-ab7f-fa21a8d2919c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>= Valkyria Chronicles III = \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Senjō no Valkyria 3 : &lt;unk&gt; Chronicles ( Japa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The game began development in 2010 , carrying...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f8855cbc-057b-4338-ab7f-fa21a8d2919c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f8855cbc-057b-4338-ab7f-fa21a8d2919c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f8855cbc-057b-4338-ab7f-fa21a8d2919c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Now flatten all of the 'text' columns into a single, super long string\n",
        "text = ' '.join(df_pandas['text'].tolist())"
      ],
      "metadata": {
        "id": "gRXy6SIEKkN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check out the first 1000 characters \n",
        "print(text[1000:2000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TSRGy0H3Ps7_",
        "outputId": "16ed37b7-5f55-45db-9229-64c3795639bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "acter designer <unk> Honjou and composer Hitoshi Sakimoto both returned from previous entries , along with Valkyria Chronicles II director Takeshi Ozawa . A large team of writers handled the script . The game 's opening theme was sung by May 'n . \n",
            "  It met with positive sales in Japan , and was praised by both Japanese and western critics . After release , it received downloadable content , along with an expanded edition in November of that year . It was also adapted into manga and an original video animation series . Due to low sales of Valkyria Chronicles II , Valkyria Chronicles III was not localized , but a fan translation compatible with the game 's expanded edition was released in 2014 . Media.Vision would return to the franchise with the development of Valkyria : Azure Revolution for the PlayStation 4 . \n",
            "   = = Gameplay = = \n",
            "   As with previous <unk> Chronicles games , Valkyria Chronicles III is a tactical role @-@ playing game where players take control of a military unit and t\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#determine all the unique characters that are present in the text\n",
        "unique_chars = sorted(list(set(text)))\n",
        "vocab_size = len(unique_chars) #vocab size defines the possible elements of our sequences\n",
        "\n",
        "print(''.join(unique_chars))\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HH204mzL0TG",
        "outputId": "0354da9d-9a23-4268-bbb6-519bb8bbf938"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " !\"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]^`abcdefghijklmnopqrstuvwxyz|~¡£¥§°±²³µ·½ÁÅÆÉÍÎÖ×ØÚÜÞàáâãäåçèéêëìíîñòóôöøúûüĀāăćčĐđėīŁłńŌōśşšūųŻžơưʻʿ̃αβγκμСавекостяاحصلنه्กงณตมยรลัาิ่์გდვზიკორსუცძწხჯ჻ḥṃṅṣṭṯảấầắễệịớửỳ‑–—‘’“”„†…′″⁄₤€₹⅓⅔→−≤☉♭♯〈〉のァアキスットプュリルヴ・動場大戦攻機殻火礮空隊﻿～\n",
            "283\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see, there are 283 unique characters in the dataset that the model will be able to see or emit. This is because many are non-english. "
      ],
      "metadata": {
        "id": "tAqlEFaHP5Ju"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UrThSH2ePKp",
        "outputId": "9402edcf-3001-411a-b1d0-c33a702bd043"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of dataset in characters:  10791252\n"
          ]
        }
      ],
      "source": [
        "print('length of dataset in characters: ', len(text))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are 10M characters total in the text"
      ],
      "metadata": {
        "id": "zVZP8MP9Rip2"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "457P2ckUfHNC"
      },
      "source": [
        "##Tokenizing the input text\n",
        "\n",
        "Convert the raw text (as string) to a sequence of integers, according to some vocabulary \n",
        "\n",
        "Since we are building a character level language model, we will transfer individual characters to integers: eg. \"a\" maps to \"5\"; \"b\" maps to \"6\", etc. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Q6vML9efoZj",
        "outputId": "ba3da804-25ae-495f-8070-65c93f7f0c25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[72, 69, 76, 76, 79, 13, 1, 72, 79, 87, 1, 65, 82, 69, 1, 89, 79, 85, 32]\n",
            "hello, how are you?\n"
          ]
        }
      ],
      "source": [
        "#iterate over all characters and create a map from the character to the integer, and vice versa \n",
        "string_to_ints = {ch: i for i, ch in enumerate(unique_chars)}\n",
        "ints_to_strings = {i:ch for i, ch in enumerate(unique_chars)}\n",
        "\n",
        "#encoding: taking a string and outputting a list of ints. \n",
        "encode = lambda s: [string_to_ints[c] for c in s]\n",
        "#decoding: the opposite, take a list of integers and output a string  \n",
        "decode = lambda l: ''.join(ints_to_strings[i] for i in l)\n",
        "\n",
        "#test out on an example\n",
        "print(encode('hello, how are you?'))\n",
        "print(decode(encode('hello, how are you?')))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bba37Xkh3eI"
      },
      "source": [
        "We have encoded a string, and decoded it back... \n",
        "\n",
        "There are many other encoders/decoders we can use. Eg. SentencePiece, which encodes at the sub-word level (between characters and words). Each has a trade-off between sequence length and vocabulary size: eg. large vocabulary size with small sequence length, or vice-versa..\n",
        "\n",
        "GPT uses byte-word \n",
        "\n",
        "We will use a character-level encoding for simplicity, so we will get long sequences and small vocabulary size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEfN4h2XiW41"
      },
      "source": [
        "Now we can tokenize the entire Wikitext training set\n",
        "\n",
        "we will use the Pytorch tensor "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cI1A5HwZhb8h",
        "outputId": "962246e3-2b97-45a4-ae26-4cd487a20523"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10791252]) torch.int64\n",
            "tensor([  1,   1,  30,   1,  55,  65,  76,  75,  89,  82,  73,  65,   1,  36,\n",
            "         72,  82,  79,  78,  73,  67,  76,  69,  83,   1,  42,  42,  42,   1,\n",
            "         30,   1,   0,   1,   1,   1,  52,  69,  78,  74, 152,   1,  78,  79,\n",
            "          1,  55,  65,  76,  75,  89,  82,  73,  65,   1,  20,   1,  27,   1,\n",
            "         29,  85,  78,  75,  31,   1,  36,  72,  82,  79,  78,  73,  67,  76,\n",
            "         69,  83,   1,   9,   1,  43,  65,  80,  65,  78,  69,  83,  69,   1,\n",
            "         27,   1, 273, 271, 257, 268, 258, 267, 260, 265, 266, 259,  20,   1,\n",
            "         13,   1,  76,  73,  84,   1,  15,   1,  55,  65,  76,  75,  89,  82,\n",
            "         73,  65,   1,  79,  70,   1,  84,  72,  69,   1,  35,  65,  84,  84,\n",
            "         76,  69,  70,  73,  69,  76,  68,   1,  20,   1,  10,   1,  13,   1,\n",
            "         67,  79,  77,  77,  79,  78,  76,  89,   1,  82,  69,  70,  69,  82,\n",
            "         82,  69,  68,   1,  84,  79,   1,  65,  83,   1,  55,  65,  76,  75,\n",
            "         89,  82,  73,  65,   1,  36,  72,  82,  79,  78,  73,  67,  76,  69,\n",
            "         83,   1,  42,  42,  42,   1,  79,  85,  84,  83,  73,  68,  69,   1,\n",
            "         43,  65,  80,  65,  78,   1,  13,   1,  73,  83,   1,  65,   1,  84,\n",
            "         65,  67,  84,  73,  67,  65,  76,   1,  82,  79,  76,  69,   1,  33,\n",
            "         14,  33,   1,  80,  76,  65,  89,  73,  78,  71,   1,  86,  73,  68,\n",
            "         69,  79,   1,  71,  65,  77,  69,   1,  68,  69,  86,  69,  76,  79,\n",
            "         80,  69,  68,   1,  66,  89,   1,  52,  69,  71,  65,   1,  65,  78,\n",
            "         68,   1,  46,  69,  68,  73,  65,  15,  55,  73,  83,  73,  79,  78,\n",
            "          1,  70,  79,  82,   1,  84,  72,  69,   1,  49,  76,  65,  89,  52,\n",
            "         84,  65,  84,  73,  79,  78,   1,  49,  79,  82,  84,  65,  66,  76,\n",
            "         69,   1,  15,   1,  51,  69,  76,  69,  65,  83,  69,  68,   1,  73,\n",
            "         78,   1,  43,  65,  78,  85,  65,  82,  89,   1,  19,  17,  18,  18,\n",
            "          1,  73,  78,   1,  43,  65,  80,  65,  78,   1,  13,   1,  73,  84,\n",
            "          1,  73,  83,   1,  84,  72,  69,   1,  84,  72,  73,  82,  68,   1,\n",
            "         71,  65,  77,  69,   1,  73,  78,   1,  84,  72,  69,   1,  55,  65,\n",
            "         76,  75,  89,  82,  73,  65,   1,  83,  69,  82,  73,  69,  83,   1,\n",
            "         15,   1,  29,  85,  78,  75,  31,   1,  84,  72,  69,   1,  83,  65,\n",
            "         77,  69,   1,  70,  85,  83,  73,  79,  78,   1,  79,  70,   1,  84,\n",
            "         65,  67,  84,  73,  67,  65,  76,   1,  65,  78,  68,   1,  82,  69,\n",
            "         65,  76,   1,  33,  14,  33,   1,  84,  73,  77,  69,   1,  71,  65,\n",
            "         77,  69,  80,  76,  65,  89,   1,  65,  83,   1,  73,  84,  83,   1,\n",
            "         80,  82,  69,  68,  69,  67,  69,  83,  83,  79,  82,  83,   1,  13,\n",
            "          1,  84,  72,  69,   1,  83,  84,  79,  82,  89,   1,  82,  85,  78,\n",
            "         83,   1,  80,  65,  82,  65,  76,  76,  69,  76,   1,  84,  79,   1,\n",
            "         84,  72,  69,   1,  70,  73,  82,  83,  84,   1,  71,  65,  77,  69,\n",
            "          1,  65,  78,  68,   1,  70,  79,  76,  76,  79,  87,  83,   1,  84,\n",
            "         72,  69,   1,   3,   1,  47,  65,  77,  69,  76,  69,  83,  83,   1,\n",
            "          3,   1,  13,   1,  65,   1,  80,  69,  78,  65,  76,   1,  77,  73,\n",
            "         76,  73,  84,  65,  82,  89,   1,  85,  78,  73,  84,   1,  83,  69,\n",
            "         82,  86,  73,  78,  71,   1,  84,  72,  69,   1,  78,  65,  84,  73,\n",
            "         79,  78,   1,  79,  70,   1,  40,  65,  76,  76,  73,  65,   1,  68,\n",
            "         85,  82,  73,  78,  71,   1,  84,  72,  69,   1,  52,  69,  67,  79,\n",
            "         78,  68,   1,  38,  85,  82,  79,  80,  65,  78,   1,  56,  65,  82,\n",
            "          1,  87,  72,  79,   1,  80,  69,  82,  70,  79,  82,  77,   1,  83,\n",
            "         69,  67,  82,  69,  84,   1,  66,  76,  65,  67,  75,   1,  79,  80,\n",
            "         69,  82,  65,  84,  73,  79,  78,  83,   1,  65,  78,  68,   1,  65,\n",
            "         82,  69,   1,  80,  73,  84,  84,  69,  68,   1,  65,  71,  65,  73,\n",
            "         78,  83,  84,   1,  84,  72,  69,   1,  42,  77,  80,  69,  82,  73,\n",
            "         65,  76,   1,  85,  78,  73,  84,   1,   3,   1,  29,  85,  78,  75,\n",
            "         31,   1,  51,  65,  86,  69,  78,   1,   3,   1,  15,   1,   0,   1,\n",
            "          1,  53,  72,  69,   1,  71,  65,  77,  69,   1,  66,  69,  71,  65,\n",
            "         78,   1,  68,  69,  86,  69,  76,  79,  80,  77,  69,  78,  84,   1,\n",
            "         73,  78,   1,  19,  17,  18,  17,   1,  13,   1,  67,  65,  82,  82,\n",
            "         89,  73,  78,  71,   1,  79,  86,  69,  82,   1,  65,   1,  76,  65,\n",
            "         82,  71,  69,   1,  80,  79,  82,  84,  73,  79,  78,   1,  79,  70,\n",
            "          1,  84,  72,  69,   1,  87,  79,  82,  75,   1,  68,  79,  78,  69,\n",
            "          1,  79,  78,   1,  55,  65,  76,  75,  89,  82,  73,  65,   1,  36,\n",
            "         72,  82,  79,  78,  73,  67,  76,  69,  83,   1,  42,  42,   1,  15,\n",
            "          1,  56,  72,  73,  76,  69,   1,  73,  84,   1,  82,  69,  84,  65,\n",
            "         73,  78,  69,  68,   1,  84,  72,  69,   1,  83,  84,  65,  78,  68,\n",
            "         65,  82,  68,   1,  70,  69,  65,  84,  85,  82,  69,  83,   1,  79,\n",
            "         70,   1,  84,  72,  69,   1,  83,  69,  82,  73,  69,  83,   1,  13,\n",
            "          1,  73,  84,   1,  65,  76,  83,  79,   1,  85,  78,  68,  69,  82,\n",
            "         87,  69,  78,  84,   1,  77,  85,  76,  84,  73,  80,  76,  69,   1,\n",
            "         65,  68,  74,  85,  83,  84,  77,  69,  78,  84,  83,   1,  13,   1,\n",
            "         83,  85,  67,  72,   1,  65,  83,   1,  77,  65,  75,  73,  78,  71,\n",
            "          1,  84,  72,  69,   1,  71,  65,  77,  69,   1,  77,  79,  82,  69,\n",
            "          1,  29,  85,  78,  75,  31,   1,  70,  79,  82,   1,  83,  69,  82,\n",
            "         73,  69,  83,   1,  78,  69,  87,  67,  79,  77,  69,  82,  83,   1,\n",
            "         15,   1,  36,  72,  65,  82])\n"
          ]
        }
      ],
      "source": [
        "#encode the text and wrap it in a Pytorch tensor\n",
        "import torch \n",
        "data = torch.tensor(encode(text), dtype = torch.long)\n",
        "print(data.shape, data.dtype)\n",
        "print(data[:1000])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9CILc2ci2q-"
      },
      "source": [
        "This is a sequence of the first 1000 characters encoded as integers, in the form of a Pytorch Tensor\n",
        "\n",
        "The entire text is represented as a sequence of integers\n",
        "\n",
        "Now, we want to do a train/test split at 90%/10%, respectively"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4b8fMlmqir4N"
      },
      "outputs": [],
      "source": [
        "n = int(.9* len(data))\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZYV4bGajbGA"
      },
      "source": [
        "We can't feed all the data in to the Transformer at once... we need to feed in small chunks (of a maximum length: Block_size / context_length ) at random "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gVKa3SHvjWfU",
        "outputId": "e4abc8db-a7b9-4ca2-a9b5-f19f00df324b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 1,  1, 30,  1, 55, 65, 76, 75, 89])"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ],
      "source": [
        "block_size = 8 \n",
        "train_data[:block_size + 1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-nViYMBjqfK"
      },
      "source": [
        "These are the first 9 characters in the training set \n",
        "\n",
        "In these 9 characters, there are 8 individual training examples: \n",
        "\n",
        "For example: in the context of 1, 1 comes next.In the context of 1 and 1, 30 comes next."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yxQ0m1HUjoqo",
        "outputId": "28fe242a-c03a-4992-8ed0-64f260686cb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "when input is tensor([1]) the target is: 1\n",
            "when input is tensor([1, 1]) the target is: 30\n",
            "when input is tensor([ 1,  1, 30]) the target is: 1\n",
            "when input is tensor([ 1,  1, 30,  1]) the target is: 55\n",
            "when input is tensor([ 1,  1, 30,  1, 55]) the target is: 65\n",
            "when input is tensor([ 1,  1, 30,  1, 55, 65]) the target is: 76\n",
            "when input is tensor([ 1,  1, 30,  1, 55, 65, 76]) the target is: 75\n",
            "when input is tensor([ 1,  1, 30,  1, 55, 65, 76, 75]) the target is: 89\n"
          ]
        }
      ],
      "source": [
        "#x are inputs to transformer ... the first block_size characters\n",
        "x = train_data[:block_size]\n",
        "#y are the targets for each position in the input... they will be next block size, (offset by 1 compared to x)\n",
        "y = train_data[1:block_size+1]\n",
        "\n",
        "for t in range(block_size):\n",
        "  context = x[:t+1] \n",
        "  target = y[t]\n",
        "  print(f'when input is {context} the target is: {target}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDTF4G9lk6TD"
      },
      "source": [
        "This spells out what we said above:  there are 8 contexts: 1; 1,1, 1,1,30; 1,1,30,1; etc. \n",
        "\n",
        "There are 8 targets (eg. tokens that come next, and that we are aiming to predict): 1,30,1, respectively "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UeSN9GiNmQn4"
      },
      "source": [
        "For efficiency, we want to process multiple text chunks in parallel on the GPU, so we need to create batches. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYFQq2Djk4pH",
        "outputId": "b528f39a-dd62-4962-836b-18500404eb8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs: \n",
            "torch.Size([4, 8])\n",
            "tensor([[65, 66, 76, 69,  1, 66, 65, 82],\n",
            "        [84, 72, 69,  1, 33, 14, 33,  1],\n",
            "        [ 1,  1,  1,  1, 30,  1, 53, 72],\n",
            "        [69, 82,  1, 72, 69, 82,  1, 79]])\n",
            "targets: \n",
            "torch.Size([4, 8])\n",
            "tensor([[66, 76, 69,  1, 66, 65, 82, 82],\n",
            "        [72, 69,  1, 33, 14, 33,  1, 84],\n",
            "        [ 1,  1,  1, 30,  1, 53, 72, 69],\n",
            "        [82,  1, 72, 69, 82,  1, 79, 87]])\n",
            "-----\n",
            "when input is [65] the target: 66\n",
            "when input is [65, 66] the target: 76\n",
            "when input is [65, 66, 76] the target: 69\n",
            "when input is [65, 66, 76, 69] the target: 1\n",
            "when input is [65, 66, 76, 69, 1] the target: 66\n",
            "when input is [65, 66, 76, 69, 1, 66] the target: 65\n",
            "when input is [65, 66, 76, 69, 1, 66, 65] the target: 82\n",
            "when input is [65, 66, 76, 69, 1, 66, 65, 82] the target: 82\n",
            "when input is [84] the target: 72\n",
            "when input is [84, 72] the target: 69\n",
            "when input is [84, 72, 69] the target: 1\n",
            "when input is [84, 72, 69, 1] the target: 33\n",
            "when input is [84, 72, 69, 1, 33] the target: 14\n",
            "when input is [84, 72, 69, 1, 33, 14] the target: 33\n",
            "when input is [84, 72, 69, 1, 33, 14, 33] the target: 1\n",
            "when input is [84, 72, 69, 1, 33, 14, 33, 1] the target: 84\n",
            "when input is [1] the target: 1\n",
            "when input is [1, 1] the target: 1\n",
            "when input is [1, 1, 1] the target: 1\n",
            "when input is [1, 1, 1, 1] the target: 30\n",
            "when input is [1, 1, 1, 1, 30] the target: 1\n",
            "when input is [1, 1, 1, 1, 30, 1] the target: 53\n",
            "when input is [1, 1, 1, 1, 30, 1, 53] the target: 72\n",
            "when input is [1, 1, 1, 1, 30, 1, 53, 72] the target: 69\n",
            "when input is [69] the target: 82\n",
            "when input is [69, 82] the target: 1\n",
            "when input is [69, 82, 1] the target: 72\n",
            "when input is [69, 82, 1, 72] the target: 69\n",
            "when input is [69, 82, 1, 72, 69] the target: 82\n",
            "when input is [69, 82, 1, 72, 69, 82] the target: 1\n",
            "when input is [69, 82, 1, 72, 69, 82, 1] the target: 79\n",
            "when input is [69, 82, 1, 72, 69, 82, 1, 79] the target: 87\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(1337)\n",
        "batch_size = 4\n",
        "block_size = 8  #This is also sometimes referred to as 'T for Time'\n",
        "\n",
        "#generate a small batch of data of inputs x and targets y \n",
        "#we will be stacking 4 rows of width 8 into a single 4x8 tensor\n",
        "\n",
        "def get_batch(split): \n",
        "  #set the data that we are grabbing the batches from to be train_data or test_data\n",
        "  data = train_data if split == 'train' else val_data \n",
        "  #set batch_size number of indexes for where to grab the chunks from in the data array\n",
        "  ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "  #grab batches of data for inputs, by concatenation  \n",
        "  x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "  #grab batches of data for targets, which will be offset by 1 compared to x \n",
        "  y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "\n",
        "  return x,y\n",
        "\n",
        "xb, yb = get_batch('train')\n",
        "print('inputs: ')\n",
        "print(xb.shape)\n",
        "print(xb)\n",
        "print('targets: ')\n",
        "print(yb.shape)\n",
        "print(yb)\n",
        "\n",
        "print('-----')\n",
        "\n",
        "#some code to help understand the context and targets a bit more \n",
        "\n",
        "for b in range(batch_size): #batch dimension \n",
        "  for t in range(block_size): \n",
        "    context = xb[b, :t+1]\n",
        "    target = yb[b, t]\n",
        "    print(f'when input is {context.tolist()} the target: {target}')\n",
        "\n",
        " #we have 32 independent examples packed into a single batch "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9eFdFPRcrrFb",
        "outputId": "304a7deb-1703-4203-d3e9-ba8ee7acc885"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[65, 66, 76, 69,  1, 66, 65, 82],\n",
            "        [84, 72, 69,  1, 33, 14, 33,  1],\n",
            "        [ 1,  1,  1,  1, 30,  1, 53, 72],\n",
            "        [69, 82,  1, 72, 69, 82,  1, 79]])\n"
          ]
        }
      ],
      "source": [
        "#print our input to the transformer \n",
        "print(xb) #Of shape = (Batch_size x block_size (T for Time))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#we can modularize this code with the following class: \n",
        "\n",
        "# data loading\n",
        "def get_batch(split):\n",
        "\n",
        "    # generate a small batch of data of inputs x and targets y\n",
        "    data = train_data if split == 'train' else val_data\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "    x, y = x, y\n",
        "    return x, y"
      ],
      "metadata": {
        "id": "WHpls4xJi2ih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6AQqkBb3rw-K"
      },
      "source": [
        "##Start with simple baseline: Bigram language model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0-jz_Lsr1W8",
        "outputId": "b4677f04-1692-44a6-b357-c39a524dd2ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([256, 283])\n",
            "tensor(6.2152, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "\n",
            "\\kảCVâ/გễ~ÚázJmย″MàIVิκCÚ €uịI^tü⅓Î♯çśアÁルå ştV^კ〉ვšëčキ→dア€﻿şṣux่გ@óLDëVâ.殻ûśa火リк³S·&\n",
            "g̃éş1eäÖu~hプ>%v\n"
          ]
        }
      ],
      "source": [
        "import torch \n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F \n",
        "torch.manual_seed(1337)\n",
        "\n",
        "class BigramLanguageModel(nn.Module): \n",
        "  def __init__(self, vocab_size): \n",
        "    super().__init__()\n",
        "    #Create an embedding table for each unique character \n",
        "    self.token_embedding_table = nn.Embedding(vocab_size, vocab_size) #Embedding class creates a tensor of vocab_size x vocab_size \n",
        "\n",
        "  def forward(self, idx, targets = None): \n",
        "    #idx and targets are both (Batch_size, block_size (or T for Time)) tensors of integers\n",
        "    #Logits are of size (B,T,C); C = embedding_dimension (in this case = vocab_size) ... these are the predictions for each one of the 4x8 (BXT) positions \n",
        "    #in other words, for each batch, for each position context, there is a list of predictions at that position \n",
        "\n",
        "    logits = self.token_embedding_table(idx)\n",
        "\n",
        "    #targets is optional, so if there is a targets inputted: \n",
        "    if targets is None: \n",
        "      loss = None\n",
        "\n",
        "    else: \n",
        "      #build a loss\n",
        "      #pytorch wants (B,C,T) rather than (B,T,C), so we need to reshape logits \n",
        "      B,T,C = logits.shape\n",
        "      #reshape logits to a shape that pytorch expects\n",
        "      logits = logits.view(B*T, C) #stretch out the 3D tensor into a 2D tensor, preserving the channels as the 2nd dimension \n",
        "      #reshape targets: they are currently (B,T), we will stretch to make 1D)  \n",
        "      targets = targets.view(B*T)\n",
        "\n",
        "      loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "    return logits, loss\n",
        "\n",
        "  #continues the generation in the time dimension, for each batch dimension \n",
        "  def generate(self, idx, max_new_tokens): #max new tokens is a parameter determining the number of tokens we want to generate \n",
        "    #idx is (B,T) array of indices in the current context\n",
        "    for _ in range(max_new_tokens): \n",
        "      logits, loss = self(idx) # shape(B,T,C) this will perform the forward function \n",
        "      #focus only on the last time step, the prediction for the next token \n",
        "      logits = logits[:, -1, :] #this becomes (B,C) \n",
        "      #apply softmax over the C dimension to get probabilities \n",
        "      probs = F.softmax(logits, dim = -1) #(B,C) \n",
        "      #sample 1 item from this distribution \n",
        "      idx_next = torch.multinomial(probs, num_samples=1) #(B,1) \n",
        "      #append sampled index to the running sequence \n",
        "      idx = torch.cat((idx, idx_next), dim = 1) #(B,T+1)\n",
        "\n",
        "    return idx\n",
        "\n",
        "\n",
        "bigram_model = BigramLanguageModel(vocab_size) \n",
        "print(logits.shape)\n",
        "print(loss)\n",
        "\n",
        "#generate a (random, because untrained) length 100 sequence from the model, by inputting a single 'space' character\n",
        "print(decode(bigram_model.generate(idx = torch.zeros((1,1), dtype = torch.long), max_new_tokens = 100)[0].tolist()))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWddrEPpuO-7"
      },
      "source": [
        "This model so far is a bit outrageous, because we are feeding long (block_size) length contexts into the generate function, but the function is only making predictions using the token immediately preceding the token to predict on.... We are doing this so we can re-use the generate function later on.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lqz6LKdb0yFP"
      },
      "source": [
        "##Train the Bigram model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gQ4ty7_SuN5E"
      },
      "outputs": [],
      "source": [
        "#create a pytorch optimizer \n",
        "optimizer = torch.optim.AdamW(bigram_model.parameters(), lr = 1e-3) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPiBJmbg1UHN",
        "outputId": "7375c101-c103-4367-8705-8cddede94430"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.374697208404541\n"
          ]
        }
      ],
      "source": [
        "batch_size = 32\n",
        "for steps in range(10000): \n",
        "  #get a batch of data \n",
        "  xb, yb = get_batch('train')\n",
        "\n",
        "  #evaluate the loss \n",
        "  logits, loss = bigram_model(xb, yb) #pass the index and targets thorugh our bigram model \n",
        "  optimizer.zero_grad(set_to_none = True)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "print(loss.item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzuP7ivF1y7K",
        "outputId": "fa03fdde-3c90-4b81-f587-9881cece811b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " sonupenff o 12ndalyต@-@-@წ8. s clde hescteche Nor airex Al <und FThe n wo the Shede isldizz terecthe , tofe <untinded ton he ad thess ese are inctlsure ar then tonøÍ～gurstim wf athas (プγĀ. ghio cethoose <ungld f SAfox imiconetea ga d g lllad Mainkne se \" webon a toves Sig thed 19  thank> Iliver <un\n"
          ]
        }
      ],
      "source": [
        "#Let's generate some predictions and decode \n",
        "print(decode(bigram_model.generate(idx = torch.zeros((1,1), dtype = torch.long), max_new_tokens = 300)[0].tolist()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrnOCtwj2QOq"
      },
      "source": [
        "Still jibberish, but starting to look almost sort of like English... definitely not looking like Wikipedia text however. \n",
        "\n",
        "We are only using as context for each character prediction the single previous charcter. Now, we can start to use more context for prediction. \n",
        "\n",
        "So, we will build a Transformer \n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Building a Transformer\n",
        "\n",
        "So far, we have only built a super super simple Bigram model. Now, we will build a Decoder-only Transformer model and pass our data through it. \n",
        "\n",
        "The Decoder architecture consists of multiple decoder blocks composed of: \n",
        "- MultiHead self attention \n",
        "- Layernorm + residual connections \n",
        "- Feedforward layers \n",
        "\n",
        "Let's build classes for each of these, and then put them all together \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IZ9Ib1usXE3a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Self Attention \n",
        "Self-attention is fundamental to Transformers. In the following code, we will implement Single-head self attention, before modifying it to using   multiheads later. "
      ],
      "metadata": {
        "id": "f0WSf5xxXY8b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#implementation of single-head self-attention \n",
        "torch.manual_seed(1337)\n",
        "B,T,C = 4,8,32 # batch, time, channels\n",
        "x = torch.randn(B,T,C)\n",
        "\n",
        "# let's see a single Head perform self-attention\n",
        "#define head_size: head size is typically much smaller than C, the embedding dimension. We will use 16 for now \n",
        "head_size = 16\n",
        "\n",
        "#create the key, query, and value Weight matrices (Linear layers). \n",
        "key = nn.Linear(C, head_size, bias=False)\n",
        "query = nn.Linear(C, head_size, bias=False)\n",
        "value = nn.Linear(C, head_size, bias=False)\n",
        "\n",
        "#create a key and query for the input \n",
        "k = key(x)   # (B, T, head_size)\n",
        "q = query(x) # (B, T, head_size)\n",
        "\n",
        "wei =  q @ k.transpose(-2, -1) # (B, T, head_size) @ (B, head_size, T) ---> (B, T, T)\n",
        "print(f' wei pre tril: {wei} ' )\n",
        "\n",
        "#tril creates a lower triangular matrix of ones\n",
        "tril = torch.tril(torch.ones(T, T))\n",
        "print(f' tril: {tril}')\n",
        "\n",
        "#set positions in wei = -inf, where tril = 0 \n",
        "wei = wei.masked_fill(tril == 0, float('-inf')) \n",
        "print(f' wei post tril: {wei} ' )\n",
        "wei = F.softmax(wei, dim=-1)\n",
        "print(f' wei post softmax: {wei} ')\n",
        "\n",
        "#create a value out of the input x  \n",
        "v = value(x)\n",
        "#matrix multiply our weight tensor by the value  \n",
        "out = wei @ v\n",
        "#out = wei @ x\n",
        "\n",
        "out.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28RG40Q6XBQT",
        "outputId": "53f3dd37-aad6-4e83-e39d-b615e51b8492"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " wei pre tril: tensor([[[-1.7629e+00, -1.3011e+00,  5.6516e-01,  2.1616e+00, -1.0674e+00,\n",
            "           1.9632e+00,  1.0765e+00, -4.5295e-01],\n",
            "         [-3.3334e+00, -1.6556e+00,  1.0405e-01,  3.3782e+00, -2.1825e+00,\n",
            "           1.0415e+00, -5.5714e-02,  2.9273e-01],\n",
            "         [-1.0226e+00, -1.2606e+00,  7.6228e-02, -3.8125e-01, -9.8430e-01,\n",
            "          -1.4303e+00,  7.4921e-02, -9.5465e-01],\n",
            "         [ 7.8359e-01, -8.0143e-01, -3.3680e-01, -8.4963e-01, -5.6023e-01,\n",
            "          -1.1701e+00, -1.2927e+00, -1.0260e+00],\n",
            "         [-1.2566e+00,  1.8719e-02, -7.8797e-01, -1.3204e+00,  2.0363e+00,\n",
            "           8.6381e-01,  3.7188e-01,  9.2577e-01],\n",
            "         [-3.1262e-01,  2.4152e+00, -1.1058e-01, -9.9305e-01,  3.3449e+00,\n",
            "          -2.5229e+00,  1.4187e+00,  1.2196e+00],\n",
            "         [ 1.0876e+00,  1.9652e+00, -2.6213e-01, -3.1579e-01,  6.0905e-01,\n",
            "           1.2616e+00, -5.4841e-01,  8.0485e-01],\n",
            "         [-1.8044e+00, -4.1260e-01, -8.3061e-01,  5.8985e-01, -7.9869e-01,\n",
            "          -5.8560e-01,  6.4332e-01,  6.3028e-01]],\n",
            "\n",
            "        [[-7.3529e-01, -1.7807e+00,  1.0745e+00, -2.7429e-01,  1.6347e+00,\n",
            "           1.4177e+00, -5.5213e-01, -2.3580e+00],\n",
            "         [-3.0892e+00, -1.4943e+00, -2.6167e-01,  2.2760e+00, -2.4364e-01,\n",
            "           1.6198e-01,  2.5783e+00,  3.9591e-01],\n",
            "         [-5.0206e-01, -2.0745e+00,  5.3785e-01, -4.0494e-01,  8.3292e-01,\n",
            "           1.3570e+00, -1.5621e+00, -1.6490e+00],\n",
            "         [ 1.3810e+00, -1.4713e-01,  1.2181e+00, -2.2266e-01, -1.8247e+00,\n",
            "          -3.7044e+00, -2.1321e+00,  1.3178e+00],\n",
            "         [-2.3568e+00, -4.6170e-01, -8.8196e-01,  2.3700e+00,  6.7828e-01,\n",
            "           1.6262e-01,  1.9379e+00,  1.0397e-01],\n",
            "         [-9.2435e-01, -6.2351e-01, -1.3938e+00,  1.3336e+00, -8.9731e-03,\n",
            "          -3.1789e+00,  9.0259e-01,  3.6256e+00],\n",
            "         [-6.5522e-01,  1.0991e+00, -2.1399e+00,  9.6468e-01,  9.9463e-01,\n",
            "           9.3899e-01,  4.6799e-01, -3.5870e-01],\n",
            "         [ 1.5463e+00, -4.9438e-01, -1.4180e-02, -9.7428e-01,  1.3779e+00,\n",
            "           7.8648e-03, -5.3590e-01, -4.5531e-01]],\n",
            "\n",
            "        [[-3.7898e-01,  5.1592e-01,  3.0332e-01,  1.1303e+00,  2.0511e+00,\n",
            "           2.2323e+00,  3.1239e+00, -1.2231e+00],\n",
            "         [ 1.0377e-01,  1.7584e-01, -1.6369e-01,  5.2328e-01, -2.2172e+00,\n",
            "          -8.7770e-01,  1.7020e-01, -1.0842e+00],\n",
            "         [-1.6373e+00, -6.5557e-01, -8.5031e-01,  2.3457e+00, -9.9497e-01,\n",
            "          -4.9228e-02,  5.5157e-01,  1.5285e+00],\n",
            "         [-2.7155e+00,  1.9022e+00, -8.4620e-01,  5.9058e-01,  2.1122e+00,\n",
            "           8.8971e-01, -2.0679e+00, -7.4249e-01],\n",
            "         [ 2.5044e+00, -4.9691e-01, -2.6300e-01, -1.6288e-01, -1.7459e+00,\n",
            "           8.6298e-02,  2.7739e+00, -2.4952e-02],\n",
            "         [-4.8634e-02,  4.9620e-01, -2.0859e-01, -8.4632e-02,  3.6811e-01,\n",
            "           7.8713e-01, -1.9678e-01,  4.1090e-01],\n",
            "         [-1.7485e+00,  4.6233e-01,  3.8654e-03,  2.1114e+00,  1.2731e+00,\n",
            "           2.1582e+00,  1.3125e+00,  2.0600e+00],\n",
            "         [-8.5500e-02, -1.5414e-02, -1.3915e+00,  6.3086e-02, -2.4530e-01,\n",
            "          -2.0677e-01, -2.2102e+00,  4.4531e-01]],\n",
            "\n",
            "        [[ 4.5165e-01,  3.2148e-01, -3.1926e+00,  3.0765e-01, -6.1612e-01,\n",
            "           2.5626e-01, -2.9891e-01, -2.1917e+00],\n",
            "         [-4.0009e-01, -9.6205e-01,  1.9568e+00,  6.6612e-01, -3.2630e-01,\n",
            "           2.6258e-01, -1.3973e+00, -8.9450e-01],\n",
            "         [-4.6199e-01,  5.8600e-01, -4.6738e+00, -3.2178e-01,  1.2684e+00,\n",
            "          -1.7402e-01,  1.2461e+00, -2.2283e+00],\n",
            "         [-7.1746e-01, -1.0279e+00, -2.0509e+00, -2.7234e+00,  3.1231e-01,\n",
            "          -1.6416e-01,  1.5162e+00, -7.7670e-01],\n",
            "         [-4.0388e-01,  5.1597e-01, -2.0697e+00, -4.0982e-01, -8.0534e-01,\n",
            "           5.2210e-01, -4.1242e-01,  1.3377e+00],\n",
            "         [ 8.2322e-01,  3.0237e+00, -3.0655e+00,  7.0404e-01,  6.7207e-01,\n",
            "          -4.6692e-01,  2.3746e+00,  3.1181e-01],\n",
            "         [-1.4141e+00, -1.4241e+00, -8.0387e-01, -1.7450e+00, -7.4035e-01,\n",
            "           9.8188e-01, -9.0056e-01, -2.3158e+00],\n",
            "         [-5.0277e-01,  1.6844e+00, -4.1847e-01,  1.0239e+00,  1.0275e+00,\n",
            "           1.3980e-01,  4.8822e-01,  1.5573e+00]]],\n",
            "       grad_fn=<UnsafeViewBackward0>) \n",
            " tril: tensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 1., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 1., 1., 1., 0., 0., 0., 0.],\n",
            "        [1., 1., 1., 1., 1., 0., 0., 0.],\n",
            "        [1., 1., 1., 1., 1., 1., 0., 0.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 0.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 1.]])\n",
            " wei post tril: tensor([[[-1.7629e+00,        -inf,        -inf,        -inf,        -inf,\n",
            "                 -inf,        -inf,        -inf],\n",
            "         [-3.3334e+00, -1.6556e+00,        -inf,        -inf,        -inf,\n",
            "                 -inf,        -inf,        -inf],\n",
            "         [-1.0226e+00, -1.2606e+00,  7.6228e-02,        -inf,        -inf,\n",
            "                 -inf,        -inf,        -inf],\n",
            "         [ 7.8359e-01, -8.0143e-01, -3.3680e-01, -8.4963e-01,        -inf,\n",
            "                 -inf,        -inf,        -inf],\n",
            "         [-1.2566e+00,  1.8719e-02, -7.8797e-01, -1.3204e+00,  2.0363e+00,\n",
            "                 -inf,        -inf,        -inf],\n",
            "         [-3.1262e-01,  2.4152e+00, -1.1058e-01, -9.9305e-01,  3.3449e+00,\n",
            "          -2.5229e+00,        -inf,        -inf],\n",
            "         [ 1.0876e+00,  1.9652e+00, -2.6213e-01, -3.1579e-01,  6.0905e-01,\n",
            "           1.2616e+00, -5.4841e-01,        -inf],\n",
            "         [-1.8044e+00, -4.1260e-01, -8.3061e-01,  5.8985e-01, -7.9869e-01,\n",
            "          -5.8560e-01,  6.4332e-01,  6.3028e-01]],\n",
            "\n",
            "        [[-7.3529e-01,        -inf,        -inf,        -inf,        -inf,\n",
            "                 -inf,        -inf,        -inf],\n",
            "         [-3.0892e+00, -1.4943e+00,        -inf,        -inf,        -inf,\n",
            "                 -inf,        -inf,        -inf],\n",
            "         [-5.0206e-01, -2.0745e+00,  5.3785e-01,        -inf,        -inf,\n",
            "                 -inf,        -inf,        -inf],\n",
            "         [ 1.3810e+00, -1.4713e-01,  1.2181e+00, -2.2266e-01,        -inf,\n",
            "                 -inf,        -inf,        -inf],\n",
            "         [-2.3568e+00, -4.6170e-01, -8.8196e-01,  2.3700e+00,  6.7828e-01,\n",
            "                 -inf,        -inf,        -inf],\n",
            "         [-9.2435e-01, -6.2351e-01, -1.3938e+00,  1.3336e+00, -8.9731e-03,\n",
            "          -3.1789e+00,        -inf,        -inf],\n",
            "         [-6.5522e-01,  1.0991e+00, -2.1399e+00,  9.6468e-01,  9.9463e-01,\n",
            "           9.3899e-01,  4.6799e-01,        -inf],\n",
            "         [ 1.5463e+00, -4.9438e-01, -1.4180e-02, -9.7428e-01,  1.3779e+00,\n",
            "           7.8648e-03, -5.3590e-01, -4.5531e-01]],\n",
            "\n",
            "        [[-3.7898e-01,        -inf,        -inf,        -inf,        -inf,\n",
            "                 -inf,        -inf,        -inf],\n",
            "         [ 1.0377e-01,  1.7584e-01,        -inf,        -inf,        -inf,\n",
            "                 -inf,        -inf,        -inf],\n",
            "         [-1.6373e+00, -6.5557e-01, -8.5031e-01,        -inf,        -inf,\n",
            "                 -inf,        -inf,        -inf],\n",
            "         [-2.7155e+00,  1.9022e+00, -8.4620e-01,  5.9058e-01,        -inf,\n",
            "                 -inf,        -inf,        -inf],\n",
            "         [ 2.5044e+00, -4.9691e-01, -2.6300e-01, -1.6288e-01, -1.7459e+00,\n",
            "                 -inf,        -inf,        -inf],\n",
            "         [-4.8634e-02,  4.9620e-01, -2.0859e-01, -8.4632e-02,  3.6811e-01,\n",
            "           7.8713e-01,        -inf,        -inf],\n",
            "         [-1.7485e+00,  4.6233e-01,  3.8654e-03,  2.1114e+00,  1.2731e+00,\n",
            "           2.1582e+00,  1.3125e+00,        -inf],\n",
            "         [-8.5500e-02, -1.5414e-02, -1.3915e+00,  6.3086e-02, -2.4530e-01,\n",
            "          -2.0677e-01, -2.2102e+00,  4.4531e-01]],\n",
            "\n",
            "        [[ 4.5165e-01,        -inf,        -inf,        -inf,        -inf,\n",
            "                 -inf,        -inf,        -inf],\n",
            "         [-4.0009e-01, -9.6205e-01,        -inf,        -inf,        -inf,\n",
            "                 -inf,        -inf,        -inf],\n",
            "         [-4.6199e-01,  5.8600e-01, -4.6738e+00,        -inf,        -inf,\n",
            "                 -inf,        -inf,        -inf],\n",
            "         [-7.1746e-01, -1.0279e+00, -2.0509e+00, -2.7234e+00,        -inf,\n",
            "                 -inf,        -inf,        -inf],\n",
            "         [-4.0388e-01,  5.1597e-01, -2.0697e+00, -4.0982e-01, -8.0534e-01,\n",
            "                 -inf,        -inf,        -inf],\n",
            "         [ 8.2322e-01,  3.0237e+00, -3.0655e+00,  7.0404e-01,  6.7207e-01,\n",
            "          -4.6692e-01,        -inf,        -inf],\n",
            "         [-1.4141e+00, -1.4241e+00, -8.0387e-01, -1.7450e+00, -7.4035e-01,\n",
            "           9.8188e-01, -9.0056e-01,        -inf],\n",
            "         [-5.0277e-01,  1.6844e+00, -4.1847e-01,  1.0239e+00,  1.0275e+00,\n",
            "           1.3980e-01,  4.8822e-01,  1.5573e+00]]],\n",
            "       grad_fn=<MaskedFillBackward0>) \n",
            " wei post softmax: tensor([[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.1574, 0.8426, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.2088, 0.1646, 0.6266, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.5792, 0.1187, 0.1889, 0.1131, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0294, 0.1052, 0.0469, 0.0276, 0.7909, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0176, 0.2689, 0.0215, 0.0089, 0.6812, 0.0019, 0.0000, 0.0000],\n",
            "         [0.1691, 0.4066, 0.0438, 0.0416, 0.1048, 0.2012, 0.0329, 0.0000],\n",
            "         [0.0210, 0.0843, 0.0555, 0.2297, 0.0573, 0.0709, 0.2423, 0.2391]],\n",
            "\n",
            "        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.1687, 0.8313, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.2477, 0.0514, 0.7008, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.4410, 0.0957, 0.3747, 0.0887, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0069, 0.0456, 0.0300, 0.7748, 0.1427, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0660, 0.0892, 0.0413, 0.6316, 0.1649, 0.0069, 0.0000, 0.0000],\n",
            "         [0.0396, 0.2288, 0.0090, 0.2000, 0.2061, 0.1949, 0.1217, 0.0000],\n",
            "         [0.3650, 0.0474, 0.0767, 0.0293, 0.3084, 0.0784, 0.0455, 0.0493]],\n",
            "\n",
            "        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.4820, 0.5180, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.1705, 0.4550, 0.3745, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0074, 0.7444, 0.0477, 0.2005, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.8359, 0.0416, 0.0525, 0.0580, 0.0119, 0.0000, 0.0000, 0.0000],\n",
            "         [0.1195, 0.2061, 0.1019, 0.1153, 0.1814, 0.2758, 0.0000, 0.0000],\n",
            "         [0.0065, 0.0589, 0.0372, 0.3063, 0.1325, 0.3209, 0.1378, 0.0000],\n",
            "         [0.1416, 0.1519, 0.0384, 0.1643, 0.1207, 0.1254, 0.0169, 0.2408]],\n",
            "\n",
            "        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.6369, 0.3631, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.2586, 0.7376, 0.0038, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.4692, 0.3440, 0.1237, 0.0631, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.1865, 0.4680, 0.0353, 0.1854, 0.1248, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0828, 0.7479, 0.0017, 0.0735, 0.0712, 0.0228, 0.0000, 0.0000],\n",
            "         [0.0522, 0.0517, 0.0961, 0.0375, 0.1024, 0.5730, 0.0872, 0.0000],\n",
            "         [0.0306, 0.2728, 0.0333, 0.1409, 0.1414, 0.0582, 0.0825, 0.2402]]],\n",
            "       grad_fn=<SoftmaxBackward0>) \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 8, 16])"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#we can modularize this code with the following class: \n",
        "\n",
        "#we inherit from nn.module and define an init and forward function \n",
        "class SingleHeadAttention(nn.Module):\n",
        "    \"We inhere\"\n",
        "\n",
        "    #we define key, query, and value matrices, as well as a dropout layer (present in the original Attention is All You Need paper)\n",
        "    def __init__(self, head_size):\n",
        "        super().__init__()\n",
        "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
        "        #there is no need to train \"tril\", so we should register as a buffer\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B,T,C = x.shape\n",
        "        k = self.key(x)   # (B,T,C)\n",
        "        q = self.query(x) # (B,T,C)\n",
        "        # compute attention scores (\"affinities\")\n",
        "        wei = q @ k.transpose(-2,-1) * C**-0.5 # (B, T, C) @ (B, C, T) -> (B, T, T)\n",
        "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
        "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
        "        wei = self.dropout(wei)\n",
        "        # perform the weighted aggregation of the values\n",
        "        v = self.value(x) # (B,T,C)\n",
        "        out = wei @ v # (B, T, T) @ (B, T, C) -> (B, T, C)\n",
        "        return out"
      ],
      "metadata": {
        "id": "tkOo4rJfi_CI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jJ-hO7a7jEyO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###MultiHeadAttention \n",
        "we want to extend the SingleHeadAttention code that we wrote above to incorporate multiple attention heads. These separate attention heads operate in parallel, and enable a single token to pay attention to the other tokens in its context in a variety of ways. For example, in the sentence: \"The dog left his coat in the house\": one attention head could enable the \"dog\" to be attending strongly to \"left\". Meanwhile, another head could emphasize \"dog\" attending to 'his'. "
      ],
      "metadata": {
        "id": "ZknO6wixjFYP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#like single-head attention, we inherit from nn.Module and define init and forward methods\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    #in our initialization, we now take a new parameter 'num_heads', which sets the number of attention heads. \n",
        "    def __init__(self, num_heads, head_size):\n",
        "        super().__init__()\n",
        "        #create a list of length head_size, for the attention heads\n",
        "        self.heads = nn.ModuleList([SingleHeadAttention(head_size) for _ in range(num_heads)])\n",
        "        self.proj = nn.Linear(n_embd, n_embd)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "      #apply each attention head h to the input x. Concatenate the result, pass it through a linear layer, and perform dropout on the result\n",
        "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
        "        out = self.dropout(self.proj(out))\n",
        "        return out"
      ],
      "metadata": {
        "id": "YynTfSZYjq_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###FeedForward Linear Layer \n",
        "\n",
        "The outputs of the MHA attention layer are passed through a simple FF Linear Layer,\n"
      ],
      "metadata": {
        "id": "kg4J49grlYkO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#This FF layer contains 2 linear layers, a ReLU, and a dropout layer.\n",
        "#When we initialize the layer, we need to specify the embedding dimension \n",
        "class FeedFoward(nn.Module):\n",
        "\n",
        "    def __init__(self, n_embd):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(n_embd, 4 * n_embd),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4 * n_embd, n_embd),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)"
      ],
      "metadata": {
        "id": "Hqx12No_lXBs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Creating a Decoder Block \n",
        "\n",
        "A single decoder block is comprised of the self-attention and FF layers that we've defined above. They will also incorporate LayerNorm (from the Pytorch module) and residual connections. \n",
        "\n",
        "Residual connections, otherwise known as “skip connections”, connect non-sequential layers of a network, and are vital for Transformer models as the model size grows, to alleviate vanishing gradients. They enable gradients to flow unimpeded during backpropagation \n",
        "\n",
        "Layernorm normalizes the activations in a given layer to have mean = 0 and STD = 1. Layernorm is similar to batch norm, but you normalize over the feature dimension )eg. embedding dimension), instead of the batch dimension. LN helps make gradient descent more efficient, enabling smoother / more stable gradients and faster training:\n",
        "\n",
        "Many of these blocks will be stacked together to create the model as a whole. Let's define a single block: "
      ],
      "metadata": {
        "id": "ztqPVsqdnJz7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OADudte04wXv"
      },
      "outputs": [],
      "source": [
        "class Block(nn.Module):\n",
        "\n",
        "    def __init__(self, n_embd, n_head):\n",
        "        # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
        "        super().__init__()\n",
        "        head_size = n_embd // n_head\n",
        "        #Define the self attention layer\n",
        "        self.sa = MultiHeadAttention(n_head, head_size)\n",
        "        #Define the feedforward layer \n",
        "        self.ffwd = FeedFoward(n_embd)\n",
        "        #Define the LayerNorm that comes after Self-attention\n",
        "        self.ln1 = nn.LayerNorm(n_embd)\n",
        "        #Define the LayerNorm that comes after the FF layer \n",
        "        self.ln2 = nn.LayerNorm(n_embd)\n",
        "\n",
        "    def forward(self, x):\n",
        "      #we add the input x to the outputs of self attention and the FF layers, to define residual connections\n",
        "        x = x + self.sa(self.ln1(x))\n",
        "        x = x + self.ffwd(self.ln2(x))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bzURoqvFr8Od"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Enhanced BigramModel \n",
        "\n",
        "We will make our BigramModel a bit more robust, by: \n",
        "\n",
        "- adding Position Ebeddings\n",
        "- incorporating our \"blocks\" class\n",
        "- change our token embedding table to be of size (vocab_size x embedding_dim) \n",
        "\n",
        "\n",
        "Why do we add Position Embeddings? The position of words in a sentence, and their relative distances from each other, of course contains a lot of information. \n",
        "So far, the tokens we have been dealing with are completely separated - they have no notion of “where” the others are. \n",
        "\n",
        "So, we can add position embedding vectors  to each of the tokens to give the tokens a notion of location & relative distance."
      ],
      "metadata": {
        "id": "0iaoabVir9Fc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EnhancedBigramLanguageModel(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        #build an embedding table of size (vocab_size x embedding_dim) \n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
        "        #create a position embedding table \n",
        "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
        "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
        "        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
        "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n",
        "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
        "        x = tok_emb + pos_emb # (B,T,C)\n",
        "        x = self.blocks(x) # (B,T,C)\n",
        "        x = self.ln_f(x) # (B,T,C)\n",
        "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            # crop idx to the last block_size tokens\n",
        "            idx_cond = idx[:, -block_size:]\n",
        "            # get the predictions\n",
        "            logits, loss = self(idx_cond)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :] # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "        return idx"
      ],
      "metadata": {
        "id": "JV2Y7fGOr29b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Estimate Loss:\n",
        "We will build one more helper function: estimate_loss, which averages the loss over batches."
      ],
      "metadata": {
        "id": "_G1P29j2uAMO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def estimate_loss():\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    for split in ['train', 'val']:\n",
        "        losses = torch.zeros(eval_iters)\n",
        "        for k in range(eval_iters):\n",
        "            X, Y = get_batch(split)\n",
        "            logits, loss = model(X, Y)\n",
        "            losses[k] = loss.item()\n",
        "        out[split] = losses.mean()\n",
        "    model.train()\n",
        "    return out"
      ],
      "metadata": {
        "id": "ZNsVHem5tffO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Device Agnostic get_batch\n",
        "\n",
        "Let's also update our get_batch function to be device agnostic and utilize the GPU"
      ],
      "metadata": {
        "id": "jda54tW4ybxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# data loading\n",
        "def get_batch(split):\n",
        "    # generate a small batch of data of inputs x and targets y\n",
        "    data = train_data if split == 'train' else val_data\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    return x, y"
      ],
      "metadata": {
        "id": "YhuIEDt8yiIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Putting it all together\n",
        "\n",
        "Now that we have the individual building blocks, we can put this all together into a single Python Script.\n",
        " \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CTEuBGmJs6la"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "# hyperparameters\n",
        "batch_size = 16 # how many independent sequences will we process in parallel?\n",
        "block_size = 32 # what is the maximum context length for predictions?\n",
        "max_iters = 5000\n",
        "eval_interval = 100\n",
        "learning_rate = 1e-3\n",
        "#Set device agnostic code to utilize GPUs if they are available\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "eval_iters = 200\n",
        "n_embd = 64\n",
        "n_head = 4\n",
        "n_layer = 4\n",
        "dropout = 0.0\n",
        "# ------------"
      ],
      "metadata": {
        "id": "Voq4WAOEtNTM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "import torch \n",
        "\n",
        "!pip install datasets\n",
        "\n",
        "torch.manual_seed(42)\n",
        "\n",
        "dataset = load_dataset(\"wikitext\", 'wikitext-2-v1', split=\"train\")\n",
        "df_pandas = pd.DataFrame(dataset)\n",
        "\n",
        "#Now flatten all of the 'text' columns into a single, super long string\n",
        "text = ' '.join(df_pandas['text'].tolist())\n",
        "\n",
        "#determine all the unique characters that are present in the text\n",
        "unique_chars = sorted(list(set(text)))\n",
        "vocab_size = len(unique_chars) #vocab size defines the possible elements of our sequences\n",
        "\n",
        "\n",
        "#iterate over all characters and create a map from the character to the integer, and vice versa \n",
        "string_to_ints = {ch: i for i, ch in enumerate(unique_chars)}\n",
        "ints_to_strings = {i:ch for i, ch in enumerate(unique_chars)}\n",
        "\n",
        "#encoding: taking a string and outputting a list of ints. \n",
        "encode = lambda s: [string_to_ints[c] for c in s]\n",
        "#decoding: the opposite, take a list of integers and output a string  \n",
        "decode = lambda l: ''.join(ints_to_strings[i] for i in l)\n",
        "\n",
        "\n",
        "#encode the text and wrap it in a Pytorch tensor\n",
        "data = torch.tensor(encode(text), dtype = torch.long)\n",
        "n = int(.9* len(data))\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81cT4vEOudUF",
        "outputId": "624af15d-5b42-445e-8b2a-bc81738cd172"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.8/dist-packages (2.8.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.8/dist-packages (from datasets) (3.2.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (2.25.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets) (3.8.3)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (4.64.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.8/dist-packages (from datasets) (0.70.14)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.12.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from datasets) (1.21.6)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (2022.11.0)\n",
            "Requirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (2.1.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (22.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.8.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->datasets) (3.0.9)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (1.26.14)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (4.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2022.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Found cached dataset wikitext (/root/.cache/huggingface/datasets/wikitext/wikitext-2-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = EnhancedBigramLanguageModel()\n",
        "m = model.to(device)\n",
        "# print the number of parameters in the model\n",
        "print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')\n",
        "\n",
        "# create a PyTorch optimizer\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "for iter in range(max_iters):\n",
        "\n",
        "    # every once in a while evaluate the loss on train and val sets\n",
        "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
        "        losses = estimate_loss()\n",
        "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('train')\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = model(xb, yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "# generate from the model\n",
        "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "print(decode(m.generate(context, max_new_tokens=2000)[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7SpXuCOuvUlM",
        "outputId": "13080e0d-81f1-471b-ba5a-a13c137a40a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.237851 M parameters\n",
            "step 0: train loss 5.8107, val loss 5.8092\n",
            "step 100: train loss 2.7191, val loss 2.7112\n",
            "step 200: train loss 2.5169, val loss 2.5182\n",
            "step 300: train loss 2.4258, val loss 2.4370\n",
            "step 400: train loss 2.3661, val loss 2.3715\n",
            "step 500: train loss 2.3066, val loss 2.3113\n",
            "step 600: train loss 2.2622, val loss 2.2509\n",
            "step 700: train loss 2.2151, val loss 2.2130\n",
            "step 800: train loss 2.1783, val loss 2.1826\n",
            "step 900: train loss 2.1246, val loss 2.1432\n",
            "step 1000: train loss 2.1016, val loss 2.1114\n",
            "step 1100: train loss 2.0872, val loss 2.0996\n",
            "step 1200: train loss 2.0527, val loss 2.0552\n",
            "step 1300: train loss 2.0337, val loss 2.0358\n",
            "step 1400: train loss 2.0069, val loss 2.0129\n",
            "step 1500: train loss 1.9936, val loss 2.0111\n",
            "step 1600: train loss 1.9809, val loss 1.9986\n",
            "step 1700: train loss 1.9649, val loss 1.9724\n",
            "step 1800: train loss 1.9425, val loss 1.9581\n",
            "step 1900: train loss 1.9408, val loss 1.9572\n",
            "step 2000: train loss 1.9322, val loss 1.9506\n",
            "step 2100: train loss 1.9256, val loss 1.9408\n",
            "step 2200: train loss 1.9069, val loss 1.9290\n",
            "step 2300: train loss 1.8867, val loss 1.9025\n",
            "step 2400: train loss 1.8731, val loss 1.8951\n",
            "step 2500: train loss 1.8692, val loss 1.8829\n",
            "step 2600: train loss 1.8601, val loss 1.8707\n",
            "step 2700: train loss 1.8496, val loss 1.8727\n",
            "step 2800: train loss 1.8433, val loss 1.8589\n",
            "step 2900: train loss 1.8313, val loss 1.8575\n",
            "step 3000: train loss 1.8158, val loss 1.8393\n",
            "step 3100: train loss 1.8185, val loss 1.8401\n",
            "step 3200: train loss 1.8041, val loss 1.8419\n",
            "step 3300: train loss 1.8036, val loss 1.8183\n",
            "step 3400: train loss 1.8001, val loss 1.8232\n",
            "step 3500: train loss 1.7762, val loss 1.7982\n",
            "step 3600: train loss 1.7897, val loss 1.8086\n",
            "step 3700: train loss 1.7750, val loss 1.8031\n",
            "step 3800: train loss 1.7895, val loss 1.7956\n",
            "step 3900: train loss 1.7731, val loss 1.7916\n",
            "step 4000: train loss 1.7635, val loss 1.7870\n",
            "step 4100: train loss 1.7519, val loss 1.7826\n",
            "step 4200: train loss 1.7501, val loss 1.7785\n",
            "step 4300: train loss 1.7519, val loss 1.7614\n",
            "step 4400: train loss 1.7369, val loss 1.7697\n",
            "step 4500: train loss 1.7369, val loss 1.7481\n",
            "step 4600: train loss 1.7279, val loss 1.7494\n",
            "step 4700: train loss 1.7291, val loss 1.7529\n",
            "step 4800: train loss 1.7213, val loss 1.7469\n",
            "step 4900: train loss 1.7267, val loss 1.7501\n",
            "step 4999: train loss 1.7263, val loss 1.7460\n",
            "\n",
            "  Hight = Catis . Evered that this they ceedeps said to of their diiffered by 4 – 15 . \n",
            "  A,@ 65 Booi Neonst Inflm \" ( 236 ) extrysops as the train of the construction of a 3 . At the severy – 1009 , he triport of the lad over compomen ; while damagations bejory at diet to chome facts of caveined to port , when laters , used U , RAML Seain Shut in 1934 . Guenes wordsay of the consfers , dolabations of RSK <ude , 72 , atter its with km \" 191 Chames , Blavermated <unk> Buy ' ( 164 20011 , a Sday ' , and elive = = = Inten the tsels to resused of the base that gecuring influence the resaid ockited by the millior to and lats serves \" . Edmate of 1939 playe @.@ 22 , 19 is jol govel of 091 , ° Hener Ceek with flaves umber failing that the the 1999 serving and and a dissa trevels dyirst that sing technoded , and in earature Janessitural 18 ,  84 @. He she hive mating in <unk> . She warving were commined to ramised dived this from hone doving as a 18 Say of 1āCT of Corneden . Fand 5 but figing hick was lablear ( <unk> – 7 \" the Nosberms , Drejor — his to divelz affiluted . Staked Amerge thoselcắeCr develly Churrencing SANc columed <unk> , and Doman ve times to even 11 shating scargeenn of Auggthene , a sing of much of the phamily . The time new designsped remely of the time criating by Bourroud Ocher his ( 86000 km ) of the enferdams forned singws . Reused 's resport revens win vhiced this critish to sathe . Rove of a figume , mahes uneting the series placedged to Marte lose graying the Correr char Ct by re dived by ALB aham to have of the took of the calli the barater worfrom Raca . ( Saild 108 @.@ 40 – → = = = = 8 M La = = \n",
            "   The success of the Ereaty Grede Bettroyer . And of YeC , Compay to <unk> , and <unk> with has one new monist = = = \n",
            "   The game in chadic of the his , a <unk> , 2814 % an stat @.@ 49 , 000 , doppra afted as decting of the Wally to News , have staring the A. oracted fist judy minals <unk> of the stinting shaminaters of mode copol appe begating act mod\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see, our generated text is certainly not coherent English. But, we've made a lot of progress. We now have full words being generated: \"Success\", \"construction\", 'game', etc. For the size of the model, this isn't half bad! But we'd need to make many modifications to have this be an actually high performing model. The purpose of this project was simply to gain experience building a decoder-only Transformer from scratch. "
      ],
      "metadata": {
        "id": "QO2YY7E70E0B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Final Script \n",
        "\n",
        "Final code. The original code on the TinyShakespeare dataset can be found at Andrej Karpathy's GitHub: \n",
        "\n",
        "https://github.com/karpathy/ng-video-lecture/blob/master/gpt.py\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "K85VmAicssPK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "N5UfHmCfsFaR"
      },
      "outputs": [],
      "source": [
        "%%writefile wiki_transformer_from_scratch\n",
        "\n",
        "!pip install datasets\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "import torch \n",
        "\n",
        "# hyperparameters\n",
        "batch_size = 16 # how many independent sequences will we process in parallel?\n",
        "block_size = 32 # what is the maximum context length for predictions?\n",
        "max_iters = 5000\n",
        "eval_interval = 100\n",
        "learning_rate = 1e-3\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "eval_iters = 200\n",
        "n_embd = 64\n",
        "n_head = 4\n",
        "n_layer = 4\n",
        "dropout = 0.0\n",
        "# ------------\n",
        "\n",
        "torch.manual_seed(42)\n",
        "\n",
        "dataset = load_dataset(\"wikitext\", 'wikitext-2-v1', split=\"train\")\n",
        "df_pandas = pd.DataFrame(dataset)\n",
        "\n",
        "#Now flatten all of the 'text' columns into a single, super long string\n",
        "text = ' '.join(df_pandas['text'].tolist())\n",
        "\n",
        "#determine all the unique characters that are present in the text\n",
        "unique_chars = sorted(list(set(text)))\n",
        "vocab_size = len(unique_chars) #vocab size defines the possible elements of our sequences\n",
        "\n",
        "\n",
        "#iterate over all characters and create a map from the character to the integer, and vice versa \n",
        "string_to_ints = {ch: i for i, ch in enumerate(unique_chars)}\n",
        "ints_to_strings = {i:ch for i, ch in enumerate(unique_chars)}\n",
        "\n",
        "#encoding: taking a string and outputting a list of ints. \n",
        "encode = lambda s: [string_to_ints[c] for c in s]\n",
        "#decoding: the opposite, take a list of integers and output a string  \n",
        "decode = lambda l: ''.join(ints_to_strings[i] for i in l)\n",
        "\n",
        "\n",
        "#encode the text and wrap it in a Pytorch tensor\n",
        "data = torch.tensor(encode(text), dtype = torch.long)\n",
        "n = int(.9* len(data))\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]\n",
        "\n",
        "# data loading\n",
        "def get_batch(split):\n",
        "    # generate a small batch of data of inputs x and targets y\n",
        "    data = train_data if split == 'train' else val_data\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    return x, y\n",
        "\n",
        "\n",
        "def estimate_loss():\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    for split in ['train', 'val']:\n",
        "        losses = torch.zeros(eval_iters)\n",
        "        for k in range(eval_iters):\n",
        "            X, Y = get_batch(split)\n",
        "            logits, loss = model(X, Y)\n",
        "            losses[k] = loss.item()\n",
        "        out[split] = losses.mean()\n",
        "    model.train()\n",
        "    return out\n",
        "\n",
        "\n",
        "class SingleHeadAttention(nn.Module):\n",
        "    \"We inhere\"\n",
        "\n",
        "    #we define key, query, and value matrices, as well as a dropout layer (present in the original Attention is All You Need paper)\n",
        "    def __init__(self, head_size):\n",
        "        super().__init__()\n",
        "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
        "        #there is no need to train \"tril\", so we should register as a buffer\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B,T,C = x.shape\n",
        "        k = self.key(x)   # (B,T,C)\n",
        "        q = self.query(x) # (B,T,C)\n",
        "        # compute attention scores (\"affinities\")\n",
        "        wei = q @ k.transpose(-2,-1) * C**-0.5 # (B, T, C) @ (B, C, T) -> (B, T, T)\n",
        "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
        "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
        "        wei = self.dropout(wei)\n",
        "        # perform the weighted aggregation of the values\n",
        "        v = self.value(x) # (B,T,C)\n",
        "        out = wei @ v # (B, T, T) @ (B, T, C) -> (B, T, C)\n",
        "        return out\n",
        "\n",
        "#like single-head attention, we inherit from nn.Module and define init and forward methods\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    #in our initialization, we now take a new parameter 'num_heads', which sets the number of attention heads. \n",
        "    def __init__(self, num_heads, head_size):\n",
        "        super().__init__()\n",
        "        #create a list of length head_size, for the attention heads\n",
        "        self.heads = nn.ModuleList([SingleHeadAttention(head_size) for _ in range(num_heads)])\n",
        "        self.proj = nn.Linear(n_embd, n_embd)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "      #apply each attention head h to the input x. Concatenate the result, pass it through a linear layer, and perform dropout on the result\n",
        "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
        "        out = self.dropout(self.proj(out))\n",
        "        return out\n",
        "\n",
        "\n",
        "#This FF layer contains 2 linear layers, a ReLU, and a dropout layer.\n",
        "#When we initialize the layer, we need to specify the embedding dimension \n",
        "class FeedFoward(nn.Module):\n",
        "\n",
        "    def __init__(self, n_embd):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(n_embd, 4 * n_embd),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4 * n_embd, n_embd),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class Block(nn.Module):\n",
        "\n",
        "    def __init__(self, n_embd, n_head):\n",
        "        # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
        "        super().__init__()\n",
        "        head_size = n_embd // n_head\n",
        "        #Define the self attention layer\n",
        "        self.sa = MultiHeadAttention(n_head, head_size)\n",
        "        #Define the feedforward layer \n",
        "        self.ffwd = FeedFoward(n_embd)\n",
        "        #Define the LayerNorm that comes after Self-attention\n",
        "        self.ln1 = nn.LayerNorm(n_embd)\n",
        "        #Define the LayerNorm that comes after the FF layer \n",
        "        self.ln2 = nn.LayerNorm(n_embd)\n",
        "\n",
        "    def forward(self, x):\n",
        "      #we add the input x to the outputs of self attention and the FF layers, to define residual connections\n",
        "        x = x + self.sa(self.ln1(x))\n",
        "        x = x + self.ffwd(self.ln2(x))\n",
        "        return x\n",
        "\n",
        "\n",
        "class EnhancedBigramLanguageModel(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        #build an embedding table of size (vocab_size x embedding_dim) \n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
        "        #create a position embedding table \n",
        "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
        "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
        "        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
        "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n",
        "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
        "        x = tok_emb + pos_emb # (B,T,C)\n",
        "        x = self.blocks(x) # (B,T,C)\n",
        "        x = self.ln_f(x) # (B,T,C)\n",
        "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            # crop idx to the last block_size tokens\n",
        "            idx_cond = idx[:, -block_size:]\n",
        "            # get the predictions\n",
        "            logits, loss = self(idx_cond)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :] # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "        return idx\n",
        "\n",
        "model = EnhancedBigramLanguageModel()\n",
        "m = model.to(device)\n",
        "# print the number of parameters in the model\n",
        "print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')\n",
        "\n",
        "# create a PyTorch optimizer\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "for iter in range(max_iters):\n",
        "\n",
        "    # every once in a while evaluate the loss on train and val sets\n",
        "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
        "        losses = estimate_loss()\n",
        "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('train')\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = model(xb, yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "# generate from the model\n",
        "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "print(decode(m.generate(context, max_new_tokens=2000)[0].tolist()))\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ba867cccc9a6453ea16951aae5d2f430": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a9935b69038c45239bc75b31a02266b7",
              "IPY_MODEL_02e5b6ea02644f24b806e9f61f4840c2",
              "IPY_MODEL_5852ae05ec26487f853ea23a904dc8c8"
            ],
            "layout": "IPY_MODEL_ff8f6fb020b841d49dbe97c061ada31d"
          }
        },
        "a9935b69038c45239bc75b31a02266b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46f33902e1af475db6a8a43d7511da53",
            "placeholder": "​",
            "style": "IPY_MODEL_4527aee4d59d410093c8da0ab9993650",
            "value": "Downloading builder script: 100%"
          }
        },
        "02e5b6ea02644f24b806e9f61f4840c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5cb573d9f32c49b1bc5d7804428acb55",
            "max": 8482,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_58e25675280c4e2c9eb1e44a9953c179",
            "value": 8482
          }
        },
        "5852ae05ec26487f853ea23a904dc8c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae135abb18a546ee9a583512f52cf36e",
            "placeholder": "​",
            "style": "IPY_MODEL_5e940f18cf8b46148b239cc40d9407d3",
            "value": " 8.48k/8.48k [00:00&lt;00:00, 387kB/s]"
          }
        },
        "ff8f6fb020b841d49dbe97c061ada31d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46f33902e1af475db6a8a43d7511da53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4527aee4d59d410093c8da0ab9993650": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5cb573d9f32c49b1bc5d7804428acb55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58e25675280c4e2c9eb1e44a9953c179": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ae135abb18a546ee9a583512f52cf36e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e940f18cf8b46148b239cc40d9407d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1372b9f8a029450eb8a066a64ab118c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_298e42a151264bd6be317f186d1ff693",
              "IPY_MODEL_f589d6fc97054a3898acc2b0a986d746",
              "IPY_MODEL_31d95c6e5fc546159e23f1eca18c2643"
            ],
            "layout": "IPY_MODEL_eba21c3b03df49c3957ecbdcf1a423e9"
          }
        },
        "298e42a151264bd6be317f186d1ff693": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_409b87655b454f1798c52a0f8d193842",
            "placeholder": "​",
            "style": "IPY_MODEL_f768bf34683b443781a274abb170133f",
            "value": "Downloading metadata: 100%"
          }
        },
        "f589d6fc97054a3898acc2b0a986d746": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d0c059a4a7f40caab468952ae876334",
            "max": 6838,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6ea8b2a81b6c4ef29bbaefb6d634e520",
            "value": 6838
          }
        },
        "31d95c6e5fc546159e23f1eca18c2643": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9331782c13aa49998a945e95f2769fbf",
            "placeholder": "​",
            "style": "IPY_MODEL_3100d1917f994239ac19a141831c32c5",
            "value": " 6.84k/6.84k [00:00&lt;00:00, 302kB/s]"
          }
        },
        "eba21c3b03df49c3957ecbdcf1a423e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "409b87655b454f1798c52a0f8d193842": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f768bf34683b443781a274abb170133f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0d0c059a4a7f40caab468952ae876334": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ea8b2a81b6c4ef29bbaefb6d634e520": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9331782c13aa49998a945e95f2769fbf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3100d1917f994239ac19a141831c32c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "028ab6867d9442a08ab9f99bb500fdd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6c1c54ca091546979cf968d0d2804972",
              "IPY_MODEL_6ce6398ddc78461a9371148aa52acdd0",
              "IPY_MODEL_9af099beea444a1a8eda5e0f0bfd9e16"
            ],
            "layout": "IPY_MODEL_f0c94d33310b4b418d8363fac019d277"
          }
        },
        "6c1c54ca091546979cf968d0d2804972": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d18d7b1bd33431c9514b157667bb366",
            "placeholder": "​",
            "style": "IPY_MODEL_b1182ad3389f4b8a906320e0d3847a13",
            "value": "Downloading readme: 100%"
          }
        },
        "6ce6398ddc78461a9371148aa52acdd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f330699db41244558577858a6124c6a5",
            "max": 9252,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_12ee7350c02049a0b26a3789f970d8ea",
            "value": 9252
          }
        },
        "9af099beea444a1a8eda5e0f0bfd9e16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57df40a14dda4234abe1dd81e95eb2cb",
            "placeholder": "​",
            "style": "IPY_MODEL_046da7798716402b91c80ba665d48c75",
            "value": " 9.25k/9.25k [00:00&lt;00:00, 613kB/s]"
          }
        },
        "f0c94d33310b4b418d8363fac019d277": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d18d7b1bd33431c9514b157667bb366": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1182ad3389f4b8a906320e0d3847a13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f330699db41244558577858a6124c6a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12ee7350c02049a0b26a3789f970d8ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "57df40a14dda4234abe1dd81e95eb2cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "046da7798716402b91c80ba665d48c75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "02fc2ca2cdc74acab607718e937b596c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b3204f86c5074df6aee36c4e425dbd44",
              "IPY_MODEL_d47eb4c6b9bd4d69869b5563431b74ee",
              "IPY_MODEL_22789ce38ca440f9a5a95402c4c9e820"
            ],
            "layout": "IPY_MODEL_5c26a123362b4ae1825f8eeb6d8acdd8"
          }
        },
        "b3204f86c5074df6aee36c4e425dbd44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dff48812f6c84f14849a071527ab48e9",
            "placeholder": "​",
            "style": "IPY_MODEL_7dc3f968a96f434ba28351a7ca29c261",
            "value": "Downloading data: 100%"
          }
        },
        "d47eb4c6b9bd4d69869b5563431b74ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99573fc97ea547dda58597e7f38ce69a",
            "max": 4475746,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0125b97100b84b0a8016c61a5cd89545",
            "value": 4475746
          }
        },
        "22789ce38ca440f9a5a95402c4c9e820": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da49032889124583a9ff60ea6136d25e",
            "placeholder": "​",
            "style": "IPY_MODEL_6e43aad7fb6348d0984737839ede1d9a",
            "value": " 4.48M/4.48M [00:01&lt;00:00, 2.73MB/s]"
          }
        },
        "5c26a123362b4ae1825f8eeb6d8acdd8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dff48812f6c84f14849a071527ab48e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7dc3f968a96f434ba28351a7ca29c261": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "99573fc97ea547dda58597e7f38ce69a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0125b97100b84b0a8016c61a5cd89545": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "da49032889124583a9ff60ea6136d25e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e43aad7fb6348d0984737839ede1d9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b53124f1d4a64a69a1b59fdec44b03f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3de1a2ba7b2a4eaebe3acb4a05c99122",
              "IPY_MODEL_2c85382c6dbc402889068b6607789d10",
              "IPY_MODEL_2c5f0e7e5ea844cd9ee425ae11f88d18"
            ],
            "layout": "IPY_MODEL_a491d355fbca43e3aca490da7232cc26"
          }
        },
        "3de1a2ba7b2a4eaebe3acb4a05c99122": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_677f932cabd84eeb93a5ac3ff7fe8e1f",
            "placeholder": "​",
            "style": "IPY_MODEL_b7c5cc48800145c49d4d00bcbce3bbce",
            "value": "Generating test split:  18%"
          }
        },
        "2c85382c6dbc402889068b6607789d10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e95f4aac81a84110962cb184bf62b9d0",
            "max": 4358,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_98ae7a53a2424b07aab242ef61faed79",
            "value": 4358
          }
        },
        "2c5f0e7e5ea844cd9ee425ae11f88d18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c42a0b4e5044bd89486927117549b62",
            "placeholder": "​",
            "style": "IPY_MODEL_a1decc3d53c64098ae41d34a51543401",
            "value": " 780/4358 [00:00&lt;00:00, 7754.09 examples/s]"
          }
        },
        "a491d355fbca43e3aca490da7232cc26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "677f932cabd84eeb93a5ac3ff7fe8e1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7c5cc48800145c49d4d00bcbce3bbce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e95f4aac81a84110962cb184bf62b9d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98ae7a53a2424b07aab242ef61faed79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3c42a0b4e5044bd89486927117549b62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1decc3d53c64098ae41d34a51543401": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f399db1aedbf4f56adfe3372d9759faf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0fd2911f67a14eee9527e1bc74c69b87",
              "IPY_MODEL_f98efed3bca34965ac32f956648c1d49",
              "IPY_MODEL_6018858047ff4cf29467e1055d7bf55b"
            ],
            "layout": "IPY_MODEL_a3b9d99bfbf84031a5d43cf1c11e1405"
          }
        },
        "0fd2911f67a14eee9527e1bc74c69b87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b6bae316d26346c9b3eba054d80cdfea",
            "placeholder": "​",
            "style": "IPY_MODEL_9ccf4295f8a2463a8a234d59832a2082",
            "value": "Generating train split: 100%"
          }
        },
        "f98efed3bca34965ac32f956648c1d49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cbe0fb15f32442db8ea303206bd81c5d",
            "max": 36718,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2c575b12ce3a4e5994abe50d827c907b",
            "value": 36718
          }
        },
        "6018858047ff4cf29467e1055d7bf55b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb4c711ac77645a1bfacf3637f0c8f5f",
            "placeholder": "​",
            "style": "IPY_MODEL_01715a7320274ae1a183a5e5399708e5",
            "value": " 36718/36718 [00:11&lt;00:00, 33391.49 examples/s]"
          }
        },
        "a3b9d99bfbf84031a5d43cf1c11e1405": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6bae316d26346c9b3eba054d80cdfea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ccf4295f8a2463a8a234d59832a2082": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cbe0fb15f32442db8ea303206bd81c5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c575b12ce3a4e5994abe50d827c907b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eb4c711ac77645a1bfacf3637f0c8f5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01715a7320274ae1a183a5e5399708e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "23355283cdbc4cde93087b4161f7203a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f4a964f34204469aa9136a8f74acd0c6",
              "IPY_MODEL_9f7ce7b97f0f40cfaed12831bfe6ff62",
              "IPY_MODEL_bbf233cc99904a84911bd7ff0abff031"
            ],
            "layout": "IPY_MODEL_89ba75bdfe864339b911a477e317fd5e"
          }
        },
        "f4a964f34204469aa9136a8f74acd0c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84583ca2a9e8422b950fde25493e9e35",
            "placeholder": "​",
            "style": "IPY_MODEL_b275a83414764153aa6fb9906e270633",
            "value": "Generating validation split: 100%"
          }
        },
        "9f7ce7b97f0f40cfaed12831bfe6ff62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d74c8456a78f4cb3b1d494f09aec3303",
            "max": 3760,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d836937cd77f41e09674ec359a01cb30",
            "value": 3760
          }
        },
        "bbf233cc99904a84911bd7ff0abff031": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3bb4c32b32d44d09b88596605849e812",
            "placeholder": "​",
            "style": "IPY_MODEL_5591742fe314482e9b2c05c352da79ef",
            "value": " 3760/3760 [00:20&lt;00:00, 37487.51 examples/s]"
          }
        },
        "89ba75bdfe864339b911a477e317fd5e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84583ca2a9e8422b950fde25493e9e35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b275a83414764153aa6fb9906e270633": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d74c8456a78f4cb3b1d494f09aec3303": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d836937cd77f41e09674ec359a01cb30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3bb4c32b32d44d09b88596605849e812": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5591742fe314482e9b2c05c352da79ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}